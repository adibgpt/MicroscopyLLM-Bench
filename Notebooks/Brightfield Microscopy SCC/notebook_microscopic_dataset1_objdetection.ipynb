{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 10142414,
          "sourceType": "datasetVersion",
          "datasetId": 6260180
        },
        {
          "sourceId": 10164524,
          "sourceType": "datasetVersion",
          "datasetId": 6276860
        },
        {
          "sourceId": 10193763,
          "sourceType": "datasetVersion",
          "datasetId": 6298535
        },
        {
          "sourceId": 185693,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": true,
          "modelInstanceId": 158308,
          "modelId": 164716
        }
      ],
      "dockerImageVersionId": 30805,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "input_file = \"/kaggle/input/txtfile/requirements.txt\"  # Replace with your file name\n",
        "output_file = \"/kaggle/working/install_requirements.txt\"\n",
        "\n",
        "with open(input_file, \"r\") as infile, open(output_file, \"w\") as outfile:\n",
        "    for line in infile:\n",
        "        line = line.strip()\n",
        "        if line:  # Avoid processing empty lines\n",
        "            outfile.write(f\"pip install {line}\\n\")\n",
        "\n",
        "print(f\"Modified file saved as {output_file}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-16T02:01:43.883186Z",
          "iopub.execute_input": "2024-12-16T02:01:43.884201Z",
          "iopub.status.idle": "2024-12-16T02:01:43.926163Z",
          "shell.execute_reply.started": "2024-12-16T02:01:43.884134Z",
          "shell.execute_reply": "2024-12-16T02:01:43.925314Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "AguWVgbUfFOh",
        "outputId": "6f34688b-4032-483e-b23d-80cadb759379"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Modified file saved as /kaggle/working/install_requirements.txt\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "zRkU1bne01vt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "656a92ec-df3e-467f-f892-8abbf2c81124"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-16T02:01:45.911344Z",
          "iopub.execute_input": "2024-12-16T02:01:45.911719Z",
          "iopub.status.idle": "2024-12-16T02:01:55.764150Z",
          "shell.execute_reply.started": "2024-12-16T02:01:45.911685Z",
          "shell.execute_reply": "2024-12-16T02:01:55.763002Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNmS8FiNKt7n",
        "outputId": "7e03abc8-ffa3-487e-f529-90001831792c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.0)\n"
          ]
        }
      ],
      "execution_count": 29
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-16T02:03:37.330774Z",
          "iopub.execute_input": "2024-12-16T02:03:37.331610Z",
          "iopub.status.idle": "2024-12-16T02:03:46.396151Z",
          "shell.execute_reply.started": "2024-12-16T02:03:37.331563Z",
          "shell.execute_reply": "2024-12-16T02:03:46.395277Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mk8RtMbQKt7o",
        "outputId": "5ff1afb9-c466-40a1-cca8-332f7a7ff89f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.5)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n"
          ]
        }
      ],
      "execution_count": 30
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_image(image_path):\n",
        "  with open(image_path, \"rb\") as image_file:\n",
        "    return base64.b64encode(image_file.read()).decode('utf-8')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-16T02:04:02.143355Z",
          "iopub.execute_input": "2024-12-16T02:04:02.143722Z",
          "iopub.status.idle": "2024-12-16T02:04:02.148487Z",
          "shell.execute_reply.started": "2024-12-16T02:04:02.143690Z",
          "shell.execute_reply": "2024-12-16T02:04:02.147629Z"
        },
        "id": "loofF6gyKt7q"
      },
      "outputs": [],
      "execution_count": 31
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "def load_image(image, input_size=448):\n",
        "    if isinstance(image, Image.Image):\n",
        "        # Convert RGBA images to RGB (discarding the alpha channel)\n",
        "        if image.mode == 'RGBA':\n",
        "            image = image.convert('RGB')\n",
        "\n",
        "        # Define the transformation (resize, convert to tensor, and normalize)\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize((input_size, input_size)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        # Apply the transformations to the image\n",
        "        tensor = transform(image).unsqueeze(0)  # Add batch dimension\n",
        "\n",
        "        # Clamp the values of the tensor to be within [0, 1]\n",
        "        tensor = tensor.clamp(0, 1)\n",
        "\n",
        "        # Move the tensor to the GPU (if needed) and convert to float32\n",
        "        return tensor.to(torch.float32).cuda()  # Use float32 here\n",
        "    else:\n",
        "        raise ValueError(\"Input must be a PIL.Image object.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-16T02:05:01.764775Z",
          "iopub.execute_input": "2024-12-16T02:05:01.765370Z",
          "iopub.status.idle": "2024-12-16T02:05:01.771479Z",
          "shell.execute_reply.started": "2024-12-16T02:05:01.765340Z",
          "shell.execute_reply": "2024-12-16T02:05:01.770554Z"
        },
        "id": "nc3Bljz7Kt7w"
      },
      "outputs": [],
      "execution_count": 33
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from PIL import Image\n",
        "import base64\n",
        "from openai import OpenAI\n",
        "from transformers import PaliGemmaForConditionalGeneration, PaliGemmaProcessor\n",
        "import torchvision.transforms as T\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from transformers import AutoProcessor, LlavaForConditionalGeneration\n",
        "\n",
        "\n",
        "\n",
        "# Configure the API key\n",
        "GOOGLE_API_KEY = \"KEEP API KEY HEre\"\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "def call_gemini_1_5_pro(text_query, image, temperature=0.4):\n",
        "    \"\"\"Call Gemini 1.5 Pro Vision model with text and image input.\"\"\"\n",
        "    model = genai.GenerativeModel('gemini-1.5-pro')\n",
        "\n",
        "    # Open the image\n",
        "\n",
        "    try:\n",
        "        # Generate content\n",
        "        response = model.generate_content(\n",
        "            [text_query, image],\n",
        "            generation_config=genai.types.GenerationConfig(\n",
        "                candidate_count=1,\n",
        "                max_output_tokens=1024,\n",
        "                temperature=temperature\n",
        "            )\n",
        "        )\n",
        "        # Return the generated response\n",
        "        return response.candidates[0].content.parts[0].text\n",
        "    except Exception as e:\n",
        "        print(f\"Error during Gemini 1.5 Pro Vision call: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "def call_gemini_1_5_flash(text_query, image, temperature=0.4):\n",
        "    \"\"\"Call Gemini 1.5 Flash Vision model with text and image input.\"\"\"\n",
        "    model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "\n",
        "    # Open the image\n",
        "\n",
        "\n",
        "    try:\n",
        "        # Generate content\n",
        "        response = model.generate_content(\n",
        "            [text_query, image],\n",
        "            generation_config=genai.types.GenerationConfig(\n",
        "                candidate_count=1,\n",
        "                max_output_tokens=1024,\n",
        "                temperature=temperature\n",
        "            )\n",
        "        )\n",
        "        # Return the generated response\n",
        "        return response.candidates[0].content.parts[0].text\n",
        "    except Exception as e:\n",
        "        print(f\"Error during Gemini 1.5 Flash Vision call: {e}\")\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "def call_gpt_vision(text_query, image_path,temperature=0.4):\n",
        "\n",
        "    # Initialize the client with API key\n",
        "    openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "    # Get the base64-encoded image\n",
        "    base64_image = encode_image(image_path)\n",
        "\n",
        "    # Construct the message with both the text query and image\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"{text_query}\\nBelow is the image I want you to analyze:\",\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": f\"![image](data:image/jpeg;base64,{base64_image})\",\n",
        "        },\n",
        "    ]\n",
        "\n",
        "    # Send the chat completion request\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        messages=messages,\n",
        "        max_tokens=300\n",
        "    )\n",
        "\n",
        "    return response['choices'][0]['message']['content']"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-16T02:05:03.406447Z",
          "iopub.execute_input": "2024-12-16T02:05:03.406831Z",
          "iopub.status.idle": "2024-12-16T02:05:03.418092Z",
          "shell.execute_reply.started": "2024-12-16T02:05:03.406795Z",
          "shell.execute_reply": "2024-12-16T02:05:03.417188Z"
        },
        "id": "77AmVlP0fFOl"
      },
      "outputs": [],
      "execution_count": 44
    },
    {
      "cell_type": "code",
      "source": [
        "def call_internvl2_vision(text_query, image):\n",
        "    # Model and Tokenizer initialization\n",
        "    path = 'OpenGVLab/InternVL2_5-1B'\n",
        "    model = AutoModel.from_pretrained(\n",
        "        path,\n",
        "        torch_dtype=torch.bfloat16,\n",
        "        low_cpu_mem_usage=True,\n",
        "        use_flash_attn=True,\n",
        "        trust_remote_code=True\n",
        "    ).eval().cuda()\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(path, trust_remote_code=True, use_fast=False)\n",
        "\n",
        "    # Load and preprocess the image\n",
        "    pixel_values = load_image(image, input_size=448).to(torch.bfloat16).cuda()\n",
        "\n",
        "    # Set generation configuration\n",
        "    generation_config = dict(max_new_tokens=512, do_sample=True)\n",
        "\n",
        "    # Create question based on text_query\n",
        "    question = f'<image>\\n{text_query}\\n'\n",
        "\n",
        "    # Perform inference\n",
        "    response = model.chat(tokenizer, pixel_values, question, generation_config)\n",
        "\n",
        "    # Return the model's response\n",
        "    return response"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-16T02:05:06.913834Z",
          "iopub.execute_input": "2024-12-16T02:05:06.914171Z",
          "iopub.status.idle": "2024-12-16T02:05:06.920028Z",
          "shell.execute_reply.started": "2024-12-16T02:05:06.914141Z",
          "shell.execute_reply": "2024-12-16T02:05:06.919047Z"
        },
        "id": "pFTNmxkxKt71"
      },
      "outputs": [],
      "execution_count": 36
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Function definitions remain the same\n",
        "def call_vision(text_query, image_path, model):\n",
        "    if model == \"gemini_1\":\n",
        "        response = call_gemini_1_5_flash(text_query, image_path)\n",
        "    elif model == \"gemini_2\":\n",
        "        response = call_gemini_1_5_pro(text_query, image_path)\n",
        "    elif model == \"gpt4\":\n",
        "        respone = call_gpt_vision(text_query, image_path)\n",
        "    elif model == \"intern_vl2\":\n",
        "        response =  call_internvl2_vision(text_query, image_path)\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "    return response\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-16T02:05:15.156454Z",
          "iopub.execute_input": "2024-12-16T02:05:15.156788Z",
          "iopub.status.idle": "2024-12-16T02:05:15.162714Z",
          "shell.execute_reply.started": "2024-12-16T02:05:15.156759Z",
          "shell.execute_reply": "2024-12-16T02:05:15.161745Z"
        },
        "id": "ZEMax1kPfFOn"
      },
      "outputs": [],
      "execution_count": 37
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_vision_prompt(dataset):\n",
        "\n",
        "    prompts = []\n",
        "\n",
        "    for row in dataset:\n",
        "\n",
        "        image, well_edge = row[\"image\"], row[\"well_edge\"]\n",
        "\n",
        "        question = \"Does the below Image contains elements of a microtiter plate well edge??\"\n",
        "\n",
        "        prompt = f\"\"\"Given the image of a cell , answer the following mutliple choice question.\n",
        "\n",
        "\n",
        "        Question: {question}\n",
        "\n",
        "        choices:\n",
        "        1)True\n",
        "        1)False\n",
        "\n",
        "        select the option and no need of explanation.\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        prompts.append({\n",
        "            \"image\": image,\n",
        "            \"true_label\": well_edge,\n",
        "            \"query\": prompt\n",
        "        })\n",
        "\n",
        "    return prompts\n",
        "\n",
        "def check_correctness(vision_response, true_label):\n",
        "    # Extract the relevant part of the response (e.g., \"False\" from \"2) False\")\n",
        "    # If the model's response is in a format like \"2) False\", split by the \")\"\n",
        "    response = vision_response.split(')')[-1].strip()  # Extract the part after \")\"\n",
        "\n",
        "    # Check if the response matches the true label\n",
        "    if response == true_label:\n",
        "        return \"True\"\n",
        "    else:\n",
        "        return \"False\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-16T02:05:18.618566Z",
          "iopub.execute_input": "2024-12-16T02:05:18.619025Z",
          "iopub.status.idle": "2024-12-16T02:05:18.627279Z",
          "shell.execute_reply.started": "2024-12-16T02:05:18.618984Z",
          "shell.execute_reply": "2024-12-16T02:05:18.626343Z"
        },
        "id": "8yOVJ4J4Kt73"
      },
      "outputs": [],
      "execution_count": 38
    },
    {
      "cell_type": "code",
      "source": [
        "# Model and options setup (replace argparse with direct variables)\n",
        "model = \"intern_vl2\"  # Specify the model to use\n",
        "\n",
        "result_dir = \"micronscopic1_benchmark\"\n",
        "\n",
        "if not os.path.exists(result_dir):\n",
        "    os.makedirs(result_dir)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-16T02:05:22.620453Z",
          "iopub.execute_input": "2024-12-16T02:05:22.620824Z",
          "iopub.status.idle": "2024-12-16T02:05:22.625555Z",
          "shell.execute_reply.started": "2024-12-16T02:05:22.620791Z",
          "shell.execute_reply": "2024-12-16T02:05:22.624740Z"
        },
        "id": "w3UNdCktKt74"
      },
      "outputs": [],
      "execution_count": 47
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"mario-dg/brightfield-microscopy-scc\",split=\"validation\")\n",
        "\n",
        "# change the ids of dataset to have only what comes after the last '/'\n",
        "dataset = dataset.map(\n",
        "    lambda x: {\n",
        "        \"image\": x[\"image\"],  # Retain the image data as is\n",
        "        \"label\": x[\"label\"],  # Extract the label\n",
        "        \"width\": x[\"width\"],  # Extract image width\n",
        "        \"height\": x[\"height\"],  # Extract image height\n",
        "        \"objects\": x[\"objects\"],  # Extract object annotations\n",
        "        \"well_edge\": x[\"well_edge\"],  # Extract well edge information\n",
        "    }\n",
        ")\n",
        "\n",
        "dataset = dataset.select(range(10))\n",
        "\n",
        "# Prepare prompts\n",
        "prompts = prepare_vision_prompt(dataset)\n",
        "\n",
        "results = []\n",
        "\n",
        "# Initialize results DataFrame\n",
        "for prompt_data in tqdm(prompts, desc=\"Evaluating Prompts\"):\n",
        "    # Extract prompt details\n",
        "    image = prompt_data[\"image\"]\n",
        "    true_label = prompt_data[\"true_label\"]\n",
        "    prompt= prompt_data[\"query\"]\n",
        "\n",
        "    # Call the vision model\n",
        "    vision_response = (\n",
        "        call_vision(prompt, image, model)\n",
        "        if model in ['gemini_1', 'gemini_2', 'gpt4','intern_vl2']\n",
        "        else \"\"\n",
        "    )\n",
        "\n",
        "    print(f\"True Label: {true_label}\\n Vision Response: {vision_response}\")\n",
        "\n",
        "\n",
        "    # Append results\n",
        "    results.append({\n",
        "        \"prompt\" : prompt,\n",
        "        \"response\": {\"vision\": vision_response},\n",
        "        \"true_label\": true_label\n",
        "    })\n",
        "\n",
        "# Convert results to a DataFrame\n",
        "df_results = pd.DataFrame(results)\n",
        "\n",
        "# Save results to a JSON file\n",
        "result_path = f\"{result_dir}/{model}_Microscopic_ObjectDetection_results.json\"\n",
        "df_results.to_json(result_path, orient=\"records\", indent=4)\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-16T02:05:25.578824Z",
          "iopub.execute_input": "2024-12-16T02:05:25.579165Z",
          "iopub.status.idle": "2024-12-16T02:24:42.823742Z",
          "shell.execute_reply.started": "2024-12-16T02:05:25.579133Z",
          "shell.execute_reply": "2024-12-16T02:24:42.822840Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuMxhC-CfFOo",
        "outputId": "f9bdc379-d934-4422-bcfd-3f0c8e885739"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluating Prompts:   0%|          | 0/10 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Evaluating Prompts:  10%|█         | 1/10 [00:04<00:38,  4.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Label: True\n",
            " Vision Response: Options could be True or False.\n",
            "\n",
            "1) True\n",
            "2) False\n",
            "\n",
            "Options could be True or False.\n",
            "\n",
            "1) True\n",
            "2) False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Evaluating Prompts:  20%|██        | 2/10 [00:07<00:29,  3.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Label: True\n",
            " Vision Response: False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Evaluating Prompts:  30%|███       | 3/10 [00:10<00:24,  3.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Label: True\n",
            " Vision Response: 1) True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Evaluating Prompts:  40%|████      | 4/10 [00:14<00:21,  3.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Label: False\n",
            " Vision Response: 1)True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Evaluating Prompts:  50%|█████     | 5/10 [00:17<00:17,  3.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Label: False\n",
            " Vision Response: 1)True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Evaluating Prompts:  60%|██████    | 6/10 [00:21<00:13,  3.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Label: False\n",
            " Vision Response: 1)False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Evaluating Prompts:  70%|███████   | 7/10 [00:24<00:10,  3.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Label: False\n",
            " Vision Response: 1) False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Evaluating Prompts:  80%|████████  | 8/10 [00:28<00:06,  3.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Label: True\n",
            " Vision Response: 1)True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Evaluating Prompts:  90%|█████████ | 9/10 [00:31<00:03,  3.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Label: False\n",
            " Vision Response: 1)True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Evaluating Prompts: 100%|██████████| 10/10 [00:34<00:00,  3.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Label: True\n",
            " Vision Response: 1) True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "execution_count": 48
    }
  ]
}